{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMo48o+7Px1615fHDFDlR4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Plant Disease Identification by using Computer Vision\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "Plants are the foundation of life on Earth, providing the oxygen we breathe, the food we eat, and countless other resources vital to our survival. However, plants, like all living organisms, are susceptible to diseases that can reduce their health, vitality, and productivity. Early detection and classification of these diseases can play a critical role in ensuring food security and maintaining ecological balance.\n",
        "\n",
        "With the advent of technology, particularly deep learning, we can now automate the process of detecting and classifying plant diseases. This project aims to build a deep learning model that can identify various plant diseases from images, enabling quicker response times and potentially saving crops.\n",
        "\n",
        "### Objectives\n",
        "**Data Preprocessing:** Before training our model, the images need to be preprocessed. This includes resizing, normalization, and data augmentation, ensuring the model is exposed to a variety of disease manifestations.\n",
        "\n",
        "**Model Building:** We utilize a custom model, ResNet9, tailored for this classification task. Deep neural networks like ResNet have been revolutionary in image classification tasks due to their ability to learn hierarchical features from images.\n",
        "\n",
        "**Training & Validation:** Training a model requires feeding it data and iteratively adjusting it to minimize errors. We'll also validate our model's performance on unseen data to ensure it generalizes well.\n",
        "\n",
        "**Evaluation:** Beyond accuracy, we'll delve into other metrics like precision, recall, and F1-score. Additionally, we'll visualize our model's predictions using a confusion matrix to understand where it might be making mistakes.\n",
        "\n",
        "### Dataset\n",
        "The dataset comprises images of various plants, both healthy and affected by a variety of diseases. Our challenge is to distinguish between these different classes based on visual patterns. Each class is organized in a folder, making it easier to preprocess and load the data.\n",
        "\n",
        "### Applications\n",
        "Once fine-tuned, such a model could be incorporated into mobile applications for farmers or botanists. By simply taking a photo of a plant leaf, they could instantly determine if the plant is healthy or identify a potential disease, allowing for timely interventions.\n",
        "\n"
      ],
      "metadata": {
        "id": "Bc-q9O-waaEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Imports & Setup\n",
        "Change the line below to reflect the actual working directory."
      ],
      "metadata": {
        "id": "qeX_mSH9hmSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"/Users/davitzi/Projects/plantDiseasesRecognition/\")\n",
        "!pwd"
      ],
      "metadata": {
        "id": "PaQxcnkFeumb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b1343b-a144-4cb7-fdf9-3f181f328448"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/Users/davitzi/Projects/plantDiseasesRecognition\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "4jtMV_KjU11j"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from models import ResNet9\n",
        "from plots import plot_loss_and_accuracy, plot_confusion_matrix, compute_metrics, plot_metrics\n",
        "from preprocess import get_dataloaders_and_classes\n",
        "from src.utils import print_diseases, print_data_frame\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also be using utility functions to print diseases and data frame summaries.\n",
        "\n"
      ],
      "metadata": {
        "id": "RXAd9pFLa97K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils import print_diseases, print_data_frame\n"
      ],
      "metadata": {
        "id": "IH3N-NTObCvp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Dataset Overview\n",
        "\n",
        "Before diving into the model training, it's crucial to understand the dataset we're working with."
      ],
      "metadata": {
        "id": "uZL9pA4TbFde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_diseases()\n"
      ],
      "metadata": {
        "id": "qgJQbdwbbJs8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75378932-b836-421b-988d-c51eecc3bc91"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique plants: \n",
            "{'Squash', 'Orange', 'Soybean', 'Grape', 'Corn_(maize)', 'Peach', 'Cherry_(including_sour)', 'Tomato', 'Pepper,_bell', 'Raspberry', 'Potato', 'Apple', 'Strawberry', 'Blueberry'}\n",
            "Total number: 14\n",
            "Unique diseases: \n",
            "{'Tomato_mosaic_virus', 'Cedar_apple_rust', 'Haunglongbing_(Citrus_greening)', 'Cercospora_leaf_spot Gray_leaf_spot', 'Common_rust_', 'Esca_(Black_Measles)', 'Early_blight', 'Late_blight', 'Spider_mites Two-spotted_spider_mite', 'Northern_Leaf_Blight', 'Leaf_scorch', 'Powdery_mildew', 'Tomato_Yellow_Leaf_Curl_Virus', 'Black_rot', 'Leaf_blight_(Isariopsis_Leaf_Spot)', 'Target_Spot', 'Septoria_leaf_spot', 'Leaf_Mold', 'Apple_scab', 'Bacterial_spot'}\n",
            "Total number: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This provides a quick overview of the unique plants and diseases in our dataset.\n",
        "\n",
        "We can see there are 14 total number of various plants as well as 20 different type of diseases, some of them sharred in common, among our classes."
      ],
      "metadata": {
        "id": "24ZYxLi7bODz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_data_frame()\n"
      ],
      "metadata": {
        "id": "B9oqRslSbRiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9acc20c6-0249-4d35-fc8e-4660efecba29"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Disease  No. of Images\n",
            "0                                Strawberry___healthy           1824\n",
            "1                                   Grape___Black_rot           1888\n",
            "2                               Potato___Early_blight           1939\n",
            "3                                 Blueberry___healthy           1816\n",
            "4                              Corn_(maize)___healthy           1859\n",
            "5                                Tomato___Target_Spot           1827\n",
            "6                                     Peach___healthy           1728\n",
            "7                                Potato___Late_blight           1939\n",
            "8                                Tomato___Late_blight           1851\n",
            "9                        Tomato___Tomato_mosaic_virus           1790\n",
            "10                             Pepper,_bell___healthy           1988\n",
            "11           Orange___Haunglongbing_(Citrus_greening)           2010\n",
            "12                                 Tomato___Leaf_Mold           1882\n",
            "13         Grape___Leaf_blight_(Isariopsis_Leaf_Spot)           1722\n",
            "14           Cherry_(including_sour)___Powdery_mildew           1683\n",
            "15                           Apple___Cedar_apple_rust           1760\n",
            "16                            Tomato___Bacterial_spot           1702\n",
            "17                                    Grape___healthy           1692\n",
            "18                              Tomato___Early_blight           1920\n",
            "19                        Corn_(maize)___Common_rust_           1907\n",
            "20                       Grape___Esca_(Black_Measles)           1920\n",
            "21                                Raspberry___healthy           1781\n",
            "22                                   Tomato___healthy           1926\n",
            "23                  Cherry_(including_sour)___healthy           1826\n",
            "24             Tomato___Tomato_Yellow_Leaf_Curl_Virus           1961\n",
            "25                                 Apple___Apple_scab           2016\n",
            "26                Corn_(maize)___Northern_Leaf_Blight           1908\n",
            "27      Tomato___Spider_mites Two-spotted_spider_mite           1741\n",
            "28                             Peach___Bacterial_spot           1838\n",
            "29                      Pepper,_bell___Bacterial_spot           1913\n",
            "30                        Tomato___Septoria_leaf_spot           1745\n",
            "31                            Squash___Powdery_mildew           1736\n",
            "32  Corn_(maize)___Cercospora_leaf_spot Gray_leaf_...           1642\n",
            "33                                  Apple___Black_rot           1987\n",
            "34                                    Apple___healthy           2008\n",
            "35                           Strawberry___Leaf_scorch           1774\n",
            "36                                   Potato___healthy           1824\n",
            "37                                  Soybean___healthy           2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By examining our data distribution, we can make informed decisions on preprocessing techniques, model selection, and evaluation metrics.\n"
      ],
      "metadata": {
        "id": "g9Cy3wEGbUNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data Preprocessing\n",
        "\n",
        "In deep learning, raw data is rarely in the right format or structure for training. Our preprocessing involves normalization, augmentation and arranging the data into a more convenient structure.\n",
        "\n",
        "Here's the preprocessing approach we're taking:"
      ],
      "metadata": {
        "id": "Yt6VTU-ybcEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "LSCmHoWqjfwu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloaders_and_classes(batch_size=32, num_samples_per_class=500):\n",
        "    train_dataset = datasets.ImageFolder(root='data/train', transform=train_transform)\n",
        "\n",
        "    # Gathering indices per class\n",
        "    indices_per_class = {}\n",
        "    for idx, (_, class_idx) in enumerate(train_dataset):\n",
        "        if class_idx not in indices_per_class:\n",
        "            indices_per_class[class_idx] = []\n",
        "        indices_per_class[class_idx].append(idx)\n",
        "\n",
        "    # Limiting number of samples per class\n",
        "    limited_indices = []\n",
        "    for class_idx, indices in indices_per_class.items():\n",
        "        limited_indices.extend(random.sample(indices, min(num_samples_per_class, len(indices))))\n",
        "\n",
        "    # Split the limited indices into train and test indices\n",
        "    train_idx, val_idx = train_test_split(limited_indices, test_size=0.2,\n",
        "                                          stratify=[train_dataset[i][1] for i in limited_indices], random_state=42)\n",
        "\n",
        "    # Creating data loaders\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    val_sampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    val_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "\n",
        "    test_set = datasets.ImageFolder(root='data/valid', transform=val_test_transform)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "    num_classes = len(train_dataset.classes)\n",
        "\n",
        "    return train_loader, val_loader, test_loader, num_classes"
      ],
      "metadata": {
        "id": "EHjEc7UxjrJf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate our dataloaders with specific transformations\n",
        "train_loader, val_loader, test_loader, num_classes = get_dataloaders_and_classes()\n"
      ],
      "metadata": {
        "id": "2zWbbiVCbeUM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Training\n",
        "\n",
        "Our choice of model is ResNet9. ResNet architectures are well-suited for image classification tasks due to their deep architectures and skip connections.\n",
        "\n",
        "### ResNet9 Model for Plant Disease Classification"
      ],
      "metadata": {
        "id": "WqbkugqBbh2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, pool=False):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.pool = pool\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = F.relu(x, inplace=True)\n",
        "        if self.pool:\n",
        "            x = F.max_pool2d(x, 4)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet9(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(ResNet9, self).__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels, 64)\n",
        "        self.conv2 = ConvBlock(64, 128, pool=True)\n",
        "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
        "\n",
        "        self.conv3 = ConvBlock(128, 256, pool=True)\n",
        "        self.conv4 = ConvBlock(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Linear(512, num_classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ek1az31vn0lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Overview:\n",
        "\n",
        "The `ResNet9` model presented here is a modified and simplified version of the standard ResNet architectures. ResNets, or Residual Networks, have been a groundbreaking innovation in the deep learning community. Their main contribution is the introduction of \"skip connections\" or \"residual connections\" that allow gradients to flow through a network. This alleviates the vanishing gradient problem in very deep networks, enabling the training of deeper models.\n",
        "\n",
        "#### **Model Architecture:**\n",
        "\n",
        "1. **ConvBlock Module**:\n",
        "    - This custom block is an encapsulation of the typical layers used in ConvNets:\n",
        "        * **Conv2D**: A convolutional layer that applies filters to the input data.\n",
        "        * **BatchNorm2D**: Batch normalization to stabilize and accelerate the training of deep networks.\n",
        "        * **ReLU**: An activation function that introduces non-linearity.\n",
        "        * **MaxPool2d** (optional): A pooling layer that reduces the spatial dimensions of the data.\n",
        "    - This block improves code modularity and reduces redundancy.\n",
        "\n",
        "2. **Convolutional and Residual Layers**:\n",
        "    - `conv1`: This is a standard convolution block without pooling, mapping `in_channels` to 64 channels.\n",
        "    - `conv2`: This block increases the channels from 64 to 128 and reduces spatial dimensions via pooling.\n",
        "    - `res1`: The first residual block that consists of two convolution blocks. The output from `conv2` is added to the output of this block. This is the essence of the \"residual connection\".\n",
        "    - `conv3`: A block that maps 128 channels to 256 with pooling.\n",
        "    - `conv4`: A block that maps 256 channels to 512 with pooling.\n",
        "    - `res2`: The second residual block, similar to `res1`. The output from `conv4` is added to the output of this block.\n",
        "\n",
        "3. **Classifier**:\n",
        "    - **AdaptiveAvgPool2d**: It reduces the spatial dimensions to 1x1. This is especially useful because irrespective of the input size, the output will always be of fixed size per batch (i.e., batch_size x 512 x 1 x 1).\n",
        "    - **Flatten**: Converts the 3D output from the previous layer to 2D.\n",
        "    - **Linear**: Fully connected layer that produces the final output with a size of `num_classes`.\n",
        "\n",
        "#### **Forward Pass**:\n",
        "\n",
        "Starting with an input `xb`:\n",
        "- The input first passes through `conv1` and `conv2`.\n",
        "- It then goes through the `res1` residual block and the result gets added to the output of `conv2`.\n",
        "- The data is further passed through `conv3` and `conv4`.\n",
        "- The output of `conv4` goes through the `res2` block and is added to the result from `conv4`.\n",
        "- Finally, the classifier produces the output with a size of `num_classes`."
      ],
      "metadata": {
        "id": "6icxSYgfn1Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DICT = {\n",
        "    'ResNet9': ResNet9\n",
        "}"
      ],
      "metadata": {
        "id": "gUIaEByycapE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "SLzi-34KcyRW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, dev, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for images, labels in tqdm(loader, desc=f\"Training epoch {epoch + 1}\", leave=False):\n",
        "        images, labels = images.to(dev), labels.to(dev)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return running_loss / len(loader.dataset), correct / total"
      ],
      "metadata": {
        "id": "iYO7JbMZci4r"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model, loader, criterion, dev, epoch):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=f\"Validating epoch {epoch + 1}\", leave=False):\n",
        "            images, labels = images.to(dev), labels.to(dev)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return running_loss / len(loader.dataset), correct / total"
      ],
      "metadata": {
        "id": "htxM5kmackEn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model_class, num_epochs, num_samples_per_class, batch_size, learning_rate):\n",
        "    if not os.path.exists('models'):\n",
        "        os.makedirs('models', exist_ok=True)\n",
        "\n",
        "    train_loader, val_loader, test_loader, num_classes = (\n",
        "        get_dataloaders_and_classes(batch_size, num_samples_per_class))\n",
        "\n",
        "    print_diseases()\n",
        "    print_data_frame()\n",
        "\n",
        "    model = model_class(3, num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list = [], [], [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_accuracy = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
        "        val_loss, val_accuracy = validate_model(model, val_loader, criterion, device, epoch)\n",
        "\n",
        "        train_loss_list.append(train_loss)\n",
        "        val_loss_list.append(val_loss)\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        val_accuracy_list.append(val_accuracy)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, \"\n",
        "            f\"Val Loss: {val_loss:.4f}, \"\n",
        "            f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
        "            f\"Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:  # Evaluate every 5 epochs\n",
        "            plot_loss_and_accuracy(str(model_class.__name__),\n",
        "                                   train_loss_list,\n",
        "                                   val_loss_list,\n",
        "                                   train_accuracy_list,\n",
        "                                   val_accuracy_list)\n",
        "\n",
        "            confusion_matrix = torch.zeros(num_classes, num_classes)\n",
        "            true_labels = []\n",
        "            predicted_labels = []\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "                        confusion_matrix[t.long(), p.long()] += 1\n",
        "                    true_labels.extend(labels.cpu().numpy())\n",
        "                    predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "            precision, recall, f1 = compute_metrics(true_labels, predicted_labels)\n",
        "            print(f\"Epoch {epoch + 1}: Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "            plot_metrics(model_class, precision, recall, f1, epoch + 1)\n",
        "            plot_confusion_matrix(model_class, confusion_matrix, val_loader.dataset.classes)\n"
      ],
      "metadata": {
        "id": "K7vRwhlUc0Q0"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is designed to handle the complete training process of a neural network model. It includes loading the data, configuring the model, defining the loss criterion, optimizing the model, training the model for a specified number of epochs, and finally evaluating the model's performance on validation data.\n",
        "\n",
        "#### Arguments:\n",
        "\n",
        "- model name\n",
        "- number of epochs\n",
        "- number of samples per class\n",
        "- number of samples per batch\n",
        "- learning rate"
      ],
      "metadata": {
        "id": "7ZHMPtxcmZAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model('ResNet9', 10, 100, 20, 0.001)"
      ],
      "metadata": {
        "id": "fLr93U99mGKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Evaluation\n",
        "\n",
        "Once our model is trained, it's imperative to evaluate its performance on unseen data to gauge its real-world applicability."
      ],
      "metadata": {
        "id": "aGD-kwWucK8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "PsihmJbwcN4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Conclusion\n",
        "\n",
        "By the end of this notebook, we've preprocessed our dataset, trained a model, and evaluated its performance. The insights from this project can be used to refine the approach, choose different architectures, or implement real-world applications for plant disease detection."
      ],
      "metadata": {
        "id": "NwvUNtzOcEYH"
      }
    }
  ]
}